{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing \n",
    "\n",
    "----------\n",
    "\n",
    "Download and inspect the data from the various sources:\n",
    "\n",
    "1. Financial Phrasebank https://huggingface.co/datasets/financial_phrasebank. Humanly annotated\n",
    "\n",
    "2. Financial tweets topics dataset: https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic/viewer/default/train?p=169. Humanly annotated\n",
    "\n",
    "Think of any pre-processing functions (\n",
    "    Converting the text to lowercase,\n",
    "    removing punctuation,\n",
    "    tokenizing the text,\n",
    "    removing stop words and empty strings,\n",
    "    lemmatizing tokens.\n",
    ") that you might need to apply for downstream tasks. As always, pick a framework for data analysis and data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('financial_phrasebank', 'sentences_50agree')\n",
    "df_fin_phrase = pd.DataFrame(dataset['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_topic_train = pd.read_csv('topic_train.csv')\n",
    "df_tweet_topic_valid = pd.read_csv('topic_valid.csv')\n",
    "df_tweet_topic = pd.concat([df_tweet_topic_train, df_tweet_topic_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet_topic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'label'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin_phrase.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin_phrase:  4846\n"
     ]
    }
   ],
   "source": [
    "print('fin_phrase: ', len(df_fin_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_topic:  21107\n"
     ]
    }
   ],
   "source": [
    "print('tweet_topic: ', len(df_tweet_topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin_phrase:  label\n",
      "1    2879\n",
      "2    1363\n",
      "0     604\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('fin_phrase: ', df_fin_phrase.label.value_counts())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_topic:  label\n",
      "0      328\n",
      "1     1051\n",
      "2     4397\n",
      "3      398\n",
      "4      456\n",
      "5     1229\n",
      "6      670\n",
      "7      784\n",
      "8      198\n",
      "9     1893\n",
      "10      82\n",
      "11      58\n",
      "12     606\n",
      "13     587\n",
      "14    2237\n",
      "15     626\n",
      "16    1234\n",
      "17     607\n",
      "18    2646\n",
      "19    1020\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('tweet_topic: ', df_tweet_topic.label.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"LABEL_0\": \"Analyst Update\",\n",
    "    \"LABEL_1\": \"Fed | Central Banks\",\n",
    "    \"LABEL_2\": \"Company | Product News\",\n",
    "    \"LABEL_3\": \"Treasuries | Corporate Debt\",\n",
    "    \"LABEL_4\": \"Dividend\",\n",
    "    \"LABEL_5\": \"Earnings\",\n",
    "    \"LABEL_6\": \"Energy | Oil\",\n",
    "    \"LABEL_7\": \"Financials\",\n",
    "    \"LABEL_8\": \"Currencies\",\n",
    "    \"LABEL_9\": \"General News | Opinion\",\n",
    "    \"LABEL_10\": \"Gold | Metals | Materials\",\n",
    "    \"LABEL_11\": \"IPO\",\n",
    "    \"LABEL_12\": \"Legal | Regulation\",\n",
    "    \"LABEL_13\": \"M&A | Investments\",\n",
    "    \"LABEL_14\": \"Macro\",\n",
    "    \"LABEL_15\": \"Markets\",\n",
    "    \"LABEL_16\": \"Politics\",\n",
    "    \"LABEL_17\": \"Personnel Change\",\n",
    "    \"LABEL_18\": \"Stock Commentary\",\n",
    "    \"LABEL_19\": \"Stock Movement\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
